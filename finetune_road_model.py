import os
import random
import torch
from torch.utils.data import DataLoader, Subset
from tqdm import tqdm

from torch.optim.lr_scheduler import ReduceLROnPlateau
from nets.attention_model import AttentionModel
from define_tsp_road import TSPRoad, RoadDataset

# â”€â”€ ì„¤ì • â”€â”€
DEVICE        = "cuda" if torch.cuda.is_available() else "cpu"
PRETRAIN      = "pretrained/tsp_100/epoch-99.pt"
DATA_PKL      = "data/road_TSP_100_fixed.pkl"
OUT_MODEL     = "pretrained/tsp_100_road_finetuned.pt"
BEST_MODEL    = "pretrained/best_road_finetuned.pt"
BATCH_SIZE    = 64
EPOCHS        = 500
LR            = 1e-5      # í•™ìŠµë¥  ë‚®ì¶¤
SCALE         = 1e5       # ê±°ë¦¬ ë‹¨ìœ„ ì¶•ì†Œ (100km ë‹¨ìœ„)
NUM_SAMPLES   = 16        # ìƒ˜í”Œë§ íšŸìˆ˜ ì¦ê°€
ENT_COEF      = 0.01      # ì—”íŠ¸ë¡œí”¼ ì •ê·œí™” ê³„ìˆ˜
FALLBACK_DIST = 60000.0   # OSRM ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê±°ë¦¬
VAL_SPLIT     = 0.1       # ê²€ì¦ì…‹ ë¹„ìœ¨
SEED          = 42
EARLY_STOPPING_PATIENCE = 50  # ê°œì„  ì—†ì„ ë•Œ ì¤‘ë‹¨

# ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ê³ ì •
random.seed(SEED)
torch.manual_seed(SEED)

# ëª¨ë¸ ì´ˆê¸°í™” ë° ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ë¡œë“œ
model = AttentionModel(
    embedding_dim=128,
    hidden_dim=128,
    n_encode_layers=3,
    n_heads=8,
    tanh_clipping=10.0,
    normalization="batch",  # LayerNorm í‚¤ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ batchnorm ì‚¬ìš©,  # LayerNorm ì ìš©
    problem=TSPRoad()
).to(DEVICE)
ckpt = torch.load(PRETRAIN, map_location=DEVICE)
model.load_state_dict(ckpt["model"], strict=False)
model.set_decode_type("sampling")

# ì˜µí‹°ë§ˆì´ì € ë° LR ìŠ¤ì¼€ì¤„ëŸ¬
opt = torch.optim.Adam(model.parameters(), lr=LR)
scheduler = ReduceLROnPlateau(opt, mode="min", factor=0.5, patience=20)

# Best ëª¨ë¸ ë° Early Stopping ë³€ìˆ˜
best_val_cost = float('inf')
no_improve_epochs = 0

# EMA ë² ì´ìŠ¤ë¼ì¸ ì´ˆê¸°í™”
ema_baseline = None

# ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„í• 
dataset = RoadDataset(DATA_PKL)
n = len(dataset)
idxs = list(range(n))
random.shuffle(idxs)
split = int(n * VAL_SPLIT)
val_idxs, train_idxs = idxs[:split], idxs[split:]
train_ds = Subset(dataset, train_idxs)
val_ds   = Subset(dataset, val_idxs)
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)

# ë””ë²„ê·¸: ë°ì´í„°ì…‹ í¬ê¸° ë° ë°°ì¹˜ ìˆ˜ í™•ì¸
print(f"ì „ì²´ ë°ì´í„°: {n}, í•™ìŠµì…‹: {len(train_idxs)}, ê²€ì¦ì…‹: {len(val_idxs)}")
print(f"í•™ìŠµìš© ë°°ì¹˜ ìˆ˜: {len(train_loader)}, ê²€ì¦ìš© ë°°ì¹˜ ìˆ˜: {len(val_loader)}")

val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)

for ep in range(1, EPOCHS+1):
    # â”€â”€ TRAIN â”€â”€
    model.train()
    total_loss = 0.0
    total_cost = 0.0
    train_pbar = tqdm(train_loader, desc=f"Train Epoch {ep}/{EPOCHS}", ncols=100)
    for batch in train_pbar:
        loc_t  = batch["loc"].to(DEVICE)
        dist_t = batch["dist"].to(DEVICE)
        # fallback ì²˜ë¦¬
        mask = torch.isinf(dist_t)
        if mask.any():
            dist_t[mask] = FALLBACK_DIST

        # multi-sample REINFORCE
        log_liks = []
        rewards  = []
        for _ in range(NUM_SAMPLES):
            _, log_likelihood, pi = model(loc_t, return_pi=True)
            cost_real, _ = TSPRoad().get_costs({"dist": dist_t}, pi)
            # ë¹„ìš©ì„ ìŒìˆ˜ ë³´ìƒìœ¼ë¡œ ì‚¬ìš©
            rewards.append((-cost_real) / SCALE)
            log_liks.append(log_likelihood)
        log_liks = torch.stack(log_liks, dim=0)   # (S, B)
        rewards  = torch.stack(rewards, dim=0)    # (S, B)

        # EMA ë² ì´ìŠ¤ë¼ì¸ ì—…ë°ì´íŠ¸
        batch_baseline = rewards.mean(dim=0, keepdim=True)
        ema_baseline   = batch_baseline if ema_baseline is None else 0.9 * ema_baseline + 0.1 * batch_baseline

        # ì–´ë“œë°´í‹°ì§€ ê³„ì‚° ë° ì •ê·œí™”
        advantages = rewards - ema_baseline
        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-6)

        # ì†ì‹¤ ê³„ì‚°
        loss_rl = -(advantages.detach() * log_liks).mean()
        ent     = -(log_liks.exp() * log_liks).mean()
        loss    = loss_rl - ENT_COEF * ent

        # ì—­ì „íŒŒ ë° ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        opt.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        opt.step()

        batch_loss = loss.item()
        batch_cost = cost_real.mean().item()
        total_loss += batch_loss
        total_cost += batch_cost

        train_pbar.set_postfix(batch_loss=f"{batch_loss:.4f}",
                               batch_cost=f"{batch_cost:.2f}")

    avg_train_loss = total_loss / len(train_loader)
    avg_train_cost = total_cost / len(train_loader)

    # â”€â”€ VALIDATION â”€â”€
    model.eval()
    model.set_decode_type("greedy")
    val_cost = 0.0
    with torch.no_grad():
        for batch in val_loader:
            loc_t  = batch["loc"].to(DEVICE)
            dist_t = batch["dist"].to(DEVICE)
            mask = torch.isinf(dist_t)
            if mask.any():
                dist_t[mask] = FALLBACK_DIST
            _, _, pi = model(loc_t, return_pi=True)
            cost_real, _ = TSPRoad().get_costs({"dist": dist_t}, pi)
            val_cost += cost_real.mean().item()
    avg_val_cost = val_cost / len(val_loader)
    model.set_decode_type("sampling")

    # â”€â”€ ì—í­ ìš”ì•½ ë¡œê·¸ â”€â”€
    print(f"[Epoch {ep}] "
          f"train_loss: {avg_train_loss:.4f} | "
          f"train_cost: {avg_train_cost:.2f} m | "
          f"val_cost:   {avg_val_cost:.2f} m")

    # â”€â”€ Best ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ â”€â”€
    if avg_val_cost < best_val_cost:
        best_val_cost = avg_val_cost
        torch.save({"model": model.state_dict()}, BEST_MODEL)
        print(f"ğŸŒŸ New best model at epoch {ep}, val_cost = {best_val_cost:.2f}")
        no_improve_epochs = 0
    else:
        no_improve_epochs += 1

    # â”€â”€ LR ìŠ¤ì¼€ì¤„ëŸ¬ ë° Early-Stopping â”€â”€
    scheduler.step(avg_val_cost)
    if no_improve_epochs > EARLY_STOPPING_PATIENCE:
        print(f"ğŸ”” Early stopping at epoch {ep} (no improvement for {no_improve_epochs} epochs)")
        break

# â”€â”€ ìµœì¢… ëª¨ë¸ ì €ì¥ â”€â”€
os.makedirs(os.path.dirname(OUT_MODEL), exist_ok=True)
torch.save({"model": model.state_dict()}, OUT_MODEL)
print(f"âœ… Saved final model to {OUT_MODEL}")
print(f"âœ… Best validation model saved to {BEST_MODEL}")

