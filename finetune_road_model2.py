import os
import random
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingLR
from tqdm import tqdm
import numpy as np

from nets.attention_model import AttentionModel
from define_tsp_road import TSPRoad, RoadDataset

# ----------------------------- #
# ì„¤ì • ë° íŒŒë¼ë¯¸í„°
# ----------------------------- #
parser = argparse.ArgumentParser()
parser.add_argument('--resume', action='store_true')
parser.add_argument('--checkpoint', type=str, default='checkpoint.pth')
parser.add_argument('--data_pkl', type=str, default='data/road_TSP_100_fixed.pkl')
parser.add_argument('--pretrain', type=str, default='pretrained/tsp_100/epoch-99.pt')
parser.add_argument('--out_model', type=str, default='pretrained/final_tsp_road.pt')
parser.add_argument('--best_model', type=str, default='pretrained/best_tsp_road.pt')
parser.add_argument('--batch_size', type=int, default=64)
parser.add_argument('--epochs', type=int, default=300)
parser.add_argument('--lr', type=float, default=3e-5)
args = parser.parse_args()

# ê¸°ë³¸ ì„¤ì •
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
PRETRAIN = args.pretrain
DATA_PKL = args.data_pkl
OUT_MODEL = args.out_model
BEST_MODEL = args.best_model
CHECKPOINT = args.checkpoint
BATCH_SIZE = args.batch_size
EPOCHS = args.epochs
LR_INIT = args.lr
ETA_MIN = 1e-7
FALLBACK_DIST = 10000.0
VAL_SPLIT = 0.1
SEED = 42
MAX_GRAD_NORM = 1.0

# Seed ê³ ì •
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# ----------------------------- #
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ----------------------------- #
def create_directory(path):
    """ë””ë ‰í† ë¦¬ ìƒì„±"""
    directory = os.path.dirname(path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)

def fix_bad_values(tensor):
    """ë¬¸ì œê°€ ìˆëŠ” í…ì„œ ê°’ ìˆ˜ì •"""
    return torch.where(
        torch.isnan(tensor) | torch.isinf(tensor), 
        torch.zeros_like(tensor), 
        tensor
    )

# ë‹¨ìœ„ í™˜ì‚° í•¨ìˆ˜
def convert_to_meters(cost):
    """ëª¨ë¸ ë¹„ìš©ì„ ë¯¸í„° ë‹¨ìœ„ë¡œ ë³€í™˜"""
    return cost * 1000  # km -> m

# ----------------------------- #
# ë©”ì¸ í•¨ìˆ˜
# ----------------------------- #
def main():
    # 1. ë””ë ‰í† ë¦¬ ìƒì„±
    create_directory(OUT_MODEL)
    create_directory(BEST_MODEL)
    create_directory(CHECKPOINT)
    
    # 2. í™˜ê²½ ë° ëª¨ë¸ ìƒì„±
    env = TSPRoad()
    model = AttentionModel(
        embedding_dim=128, 
        hidden_dim=128,
        n_encode_layers=3, 
        n_heads=8,
        tanh_clipping=10.0, 
        normalization="batch",
        problem=env
    ).to(DEVICE)
    
    # 3. ë°ì´í„° ë¡œë“œ
    print(f"ë°ì´í„°ì…‹ ë¡œë”© ì¤‘: {DATA_PKL}")
    try:
        full_dataset = RoadDataset(DATA_PKL)
        n_total = len(full_dataset)
        
        # í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ ë¶„í• 
        indices = list(range(n_total))
        random.shuffle(indices)
        split = int(n_total * VAL_SPLIT)
        train_idx, val_idx = indices[split:], indices[:split]
        
        # ë°ì´í„° ë¡œë”
        train_loader = DataLoader(
            Subset(full_dataset, train_idx), 
            batch_size=BATCH_SIZE, 
            shuffle=True
        )
        val_loader = DataLoader(
            Subset(full_dataset, val_idx), 
            batch_size=BATCH_SIZE
        )
        print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: ì´ {n_total}ê°œ (í•™ìŠµ {len(train_idx)}, ê²€ì¦ {len(val_idx)})")
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return
    
    # 4. ì˜µí‹°ë§ˆì´ì € & ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = Adam(model.parameters(), lr=LR_INIT)
    scheduler = CosineAnnealingLR(
        optimizer, 
        T_max=EPOCHS, 
        eta_min=ETA_MIN
    )
    
    # 5. ëª¨ë¸ ì´ˆê¸°í™”/ë¡œë“œ
    start_epoch = 1
    best_val_cost = float('inf')
    
    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µì›
    if args.resume and os.path.exists(CHECKPOINT):
        print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: {CHECKPOINT}")
        try:
            ckpt = torch.load(CHECKPOINT, map_location=DEVICE, weights_only=False)
            model.load_state_dict(ckpt['model'])
            optimizer.load_state_dict(ckpt['optimizer'])
            scheduler.load_state_dict(ckpt['scheduler'])
            best_val_cost = ckpt.get('best_val_cost', float('inf'))
            start_epoch = ckpt.get('epoch', 1) + 1
            print(f"ì—í¬í¬ {start_epoch}ë¶€í„° í•™ìŠµ ì¬ê°œ")
        except Exception as e:
            print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            print("ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤")
    
    # ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë“œ
    elif os.path.exists(PRETRAIN):
        print(f"ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë”©: {PRETRAIN}")
        try:
            pt = torch.load(PRETRAIN, map_location=DEVICE, weights_only=False)
            if 'model' in pt:
                model.load_state_dict(pt['model'])
            else:
                model.load_state_dict(pt)
            print("âœ… ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            print("âš ï¸ ëœë¤ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤")
    
    # 6. í•™ìŠµ ì‹œì‘
    print(f"í™˜ê²½: {DEVICE}")
    print(f"ì´ {EPOCHS}ê°œ ì—í¬í¬ í•™ìŠµ ì‹œì‘")
    
    for epoch in range(start_epoch, EPOCHS + 1):
        # í•™ìŠµ ëª¨ë“œ
        model.train()
        
        # ì—í¬í¬ í†µê³„
        epoch_loss = 0
        epoch_reward = 0
        processed_batches = 0
        
        # í•™ìŠµ ë£¨í”„
        train_pbar = tqdm(train_loader, desc=f"í•™ìŠµ {epoch}/{EPOCHS}")
        for batch_idx, batch in enumerate(train_pbar):
            try:
                # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
                loc, dist = batch['loc'].to(DEVICE), batch['dist'].to(DEVICE)
                
                # ë¹„ì •ìƒ ê°’ ì œê±°
                dist = torch.where(
                    torch.isnan(dist) | torch.isinf(dist) | (dist < 0),
                    torch.tensor(FALLBACK_DIST, device=DEVICE),
                    dist
                )
                
                # ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
                batch_input = {'loc': loc, 'dist': dist}
                
                # ì¤‘ìš”: AttentionModelì˜ ë””ì½”ë”© íƒ€ì… ëª…ì‹œì  ì„¤ì •
                model.set_decode_type('sampling')
                
                # cost, llì„ ì§ì ‘ ì–»ê¸° ìœ„í•´ ëª¨ë¸ í˜¸ì¶œ (return_pi=Falseë¡œ ì„¤ì •)
                cost, ll = model(loc)  # ëª¨ë¸ì´ cost, log_likelihood ë°˜í™˜
                
                # ì†ì‹¤ ê³„ì‚° (log_likelihoodë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ ëª©í‘œ)
                loss = -ll.mean()
                
                # ì—­ì „íŒŒ ë° ìµœì í™”
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)
                optimizer.step()
                
                # ë¯¸í„° ë‹¨ìœ„ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
                meter_cost = convert_to_meters(cost.mean().item())
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                epoch_loss += loss.item()
                epoch_reward += -meter_cost  # ë©”íŠ¸ë¦­ ë‹¨ìœ„ë¡œ ì €ì¥
                processed_batches += 1
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                train_pbar.set_postfix(
                    loss=f"{loss.item():.4f}",
                    avg_loss=f"{epoch_loss/processed_batches:.4f}",
                    reward=f"{-meter_cost:.2f}m"  # ë¯¸í„° ë‹¨ìœ„ë¡œ í‘œì‹œ
                )
            except Exception as e:
                print(f"\në°°ì¹˜ {batch_idx} í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                print(traceback.format_exc())
                continue
        
        # í•™ìŠµë¥  ì—…ë°ì´íŠ¸
        scheduler.step()
        
        # ì—í¬í¬ í†µê³„ ì¶œë ¥
        if processed_batches > 0:
            avg_loss = epoch_loss / processed_batches
            avg_reward = epoch_reward / processed_batches
            print(f"[ì—í¬í¬ {epoch:3d}] í•™ìŠµ ì†ì‹¤: {avg_loss:.4f} | ë³´ìƒ: {avg_reward:.2f}m | í•™ìŠµë¥ : {optimizer.param_groups[0]['lr']:.2e}")
        else:
            print(f"[ì—í¬í¬ {epoch:3d}] ê²½ê³ : ìœ íš¨í•œ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ê²€ì¦
        model.eval()
        model.set_decode_type('greedy')  # ê²€ì¦ì—ëŠ” greedy ì‚¬ìš©
        
        val_costs = []
        val_pbar = tqdm(val_loader, desc=f"ê²€ì¦ {epoch}/{EPOCHS}")
        
        with torch.no_grad():
            for batch in val_pbar:
                try:
                    # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
                    loc, dist = batch['loc'].to(DEVICE), batch['dist'].to(DEVICE)
                    
                    # ë¹„ì •ìƒ ê°’ ì œê±°
                    dist = torch.where(
                        torch.isnan(dist) | torch.isinf(dist) | (dist < 0),
                        torch.tensor(FALLBACK_DIST, device=DEVICE),
                        dist
                    )
                    
                    # ëª¨ë¸ ì…ë ¥
                    batch_input = {'loc': loc, 'dist': dist}
                    
                    # ê²€ì¦ì„ ìœ„í•œ ë¹„ìš© ê³„ì‚°
                    # ê²€ì¦ì—ì„œëŠ” return_pi=Trueë¡œ ì„¤ì •í•˜ì—¬ ê²½ë¡œë„ ì–»ìŒ
                    cost, _, pi = model(loc, return_pi=True)
                    
                    # ë¯¸í„° ë‹¨ìœ„ë¡œ ë³€í™˜
                    cost_meters = convert_to_meters(cost)
                    
                    # ìœ íš¨í•œ ë¹„ìš©ë§Œ ì €ì¥
                    valid_costs = cost_meters[~torch.isnan(cost_meters) & ~torch.isinf(cost_meters)]
                    if len(valid_costs) > 0:
                        val_costs.extend(valid_costs.cpu().numpy())
                
                except Exception as e:
                    print(f"ê²€ì¦ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    import traceback
                    print(traceback.format_exc())
                    continue
        
        # ê²€ì¦ ê²°ê³¼ ê³„ì‚°
        if val_costs:
            val_cost = np.mean(val_costs)
            print(f"[ì—í¬í¬ {epoch:3d}] ê²€ì¦ ë¹„ìš©: {val_cost:.2f}m")
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            if val_cost < best_val_cost:
                best_val_cost = val_cost
                torch.save({
                    'model': model.state_dict(),
                    'epoch': epoch,
                    'val_cost': val_cost
                }, BEST_MODEL)
                print(f"ğŸŒŸ ìµœê³  ëª¨ë¸ ì €ì¥ @ì—í¬í¬{epoch} (ê²€ì¦ ë¹„ìš©: {val_cost:.2f}m)")
        else:
            print(f"[ì—í¬í¬ {epoch:3d}] ê²½ê³ : ìœ íš¨í•œ ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        torch.save({
            'epoch': epoch,
            'model': model.state_dict(),
            'optimizer': optimizer.state_dict(),
            'scheduler': scheduler.state_dict(),
            'best_val_cost': best_val_cost
        }, CHECKPOINT)
        
        # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if epoch % 10 == 0:
            cp_dir = os.path.dirname(CHECKPOINT)
            if cp_dir:
                cp_path = os.path.join(cp_dir, f"checkpoint_ep{epoch}.pth")
            else:
                cp_path = f"checkpoint_ep{epoch}.pth"
                
            torch.save({
                'epoch': epoch,
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'scheduler': scheduler.state_dict(),
                'best_val_cost': best_val_cost
            }, cp_path)
            print(f"ğŸ“ ì—í¬í¬ {epoch} ì²´í¬í¬ì¸íŠ¸ ì €ì¥")
    
    # í•™ìŠµ ì™„ë£Œ
    print("\n" + "="*50)
    print(f"í•™ìŠµ ì™„ë£Œ. ìµœê³  ê²€ì¦ ë¹„ìš©: {best_val_cost:.2f}m")
    
    # ìµœì¢… ëª¨ë¸ ì €ì¥
    torch.save({
        'model': model.state_dict(),
        'best_val_cost': best_val_cost,
        'final_epoch': EPOCHS
    }, OUT_MODEL)
    
    print(f"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {OUT_MODEL}")
    print(f"âœ… ìµœê³  ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {BEST_MODEL}")

if __name__ == "__main__":
    main()